На этом чемпионате вам предстоит разработать модель машинного обучения, предлагающую лучшую следующую покупку клиенту банка, для увеличения доли покупок с данной карты в общей структуре трат клиента и повышения лояльности.

Основное направление при продаже товаров и услуг­ – это история про встраивание в контекст клиента. Решение должно представлять собой поток контекстно-обусловленных выгодных предложений (рекомендаций) клиенту по следующей покупке.

Решение должно учитывать потребности всех заинтересованных сторон. Банку это решение должно повысить количество транзакций, который совершает клиент банка. А клиент получает возможность экономить, а также и расширять свой потребительский опыт получая предложения, основанные на опыте похожих людей. Возможности по гео-таргетированным предложениям (вплоть до real-time) дают дополнительную контекстную силу подходу.

Решение может представлять рекомендацию льготных покупок карточным клиентам банка с указанием места совершения покупки, срока действия предложения, учитывающую потребности клиента и приоритеты банка.

Предложение должно удовлетворять следующим основным критериям:

- предложение должно быть интересно и релевантно клиенту (если он ходит в самые бюджетные продуктовые магазины – то получает предложения на самую бюджетную аптеку, а не дорогую; если пользуется онлайн магазинами еды – то предложение на онлайн магазин одежды и пр.)

- предложение обязательно должно расширять интенсивность использования карты клиентом (увеличивать среднее число и объем транзакций в месяц). То есть клиент через предложение должен научиться либо платить в новых товарных категориях, либо платить чаще, либо тратить больше.

В рамках всего конкурсного задания вам потребуется предобработать данные, выполнить анализ данных и выявить ключевые зависимости, построить необходимые модели машинного обучения, разработать приложение и API для пользователей сервиса.

 

На этой сессии необходимо подготовить набор данных и произвести его предобработку для дальнейшего исследования и построения моделей обучения. Так же необходимо дополнить набор геоданными на основе открытых источников.

В первой сессии нам предстоит выполнить 4 главных задания:

1) Парсинг данных

2) Предоброботка данных и выделение значимых атрибутов

3) Описание структуры набора данных

4) Подготовка отчета

Нам необходимо импортировать необходимые библиотеки, для работы с соответствующим типом файла. Для первой сессии нам хватит двух библиотек это Pandas и Numpy.

 

# импортируем Pandas и Numpy

import pandas as pd #библиотека для работы с большими файлами

import numpy as np  #библиотека для манипуляции с большими массивами позволяет выполнять ряд полезных функций

 

Так как у нас всего 2 фала, которые требуют обработки, нам не нужно создавать парсер, который бы собрал и отфильтровал информацию, но если файлов будет много то необходимо использовать библиотеку os, как мы проходили раньше.

С помощью библиотеки pandas создадим дата фреймы содержащие в себе данные наших файлов

df1 = pd.read_csv('train_1.csv', sep=';') #создание первого датафрейма содержащего в себе значения файла train_1

df1                                       #вывод на экран результата
Следуя заданию, нам необходимо создать новый атрибут, содержащий в себе геоданные и визуализировать его зависимости. Второе, классифицировать группы пользователей.

 

В качестве основных геоданных, мы возьмем город покупки, его мы можем взять из колонки LOCATION_NAME, для этого создадим парсер, который поместит названия городов в новую колонку City:

def get_city(address): #создание функции

   

    if len(address.split('\\')) > 3 and address.split('\\')[2].isalpha():#условие, если число разделенных слов больше трех и не имеет цифр, тогда верно

        city = address.split('\\')[2].strip() #вывод третьего слова из строки, с разделителем \

        return city #вывод города

    else: #если условие неверно

        return "No Name" #вывод "No Name"

 

df['City'] = df.LOCATION_NAME.apply(get_city)  #применения функции к столбцу с адресом

df = df[df["City"] != "No Name"]         #удаление значений No Name

df.City = df.City.str.capitalize()    #Изменение регистра городов: первая буква заглавная, остальные строчные

df #вывод полученного результата на экран

df2 = pd.read_csv('train_2.csv', sep=';')  #создание второго датафрейма содержащего в себе значения файла train_2

df2                                        #вывод на экран результата
Далее нам необходимо посмотреть какие «Аномалии содержит фрейм», для этого воспользуемся атрибутом .info()

df.info() #Вывод информации и датафрейме:

 

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 12845075 entries, 0 to 12845074
Data columns (total 15 columns):
 #   Column           Dtype  
---  ------           -----  
 0   ID               int64  
 1   PROD_TYPE        int64  
 2   TRANS_DTTM       object 
 3   MCC_CODE         int64  
 4   SUM_TRANS        object 
 5   LOCATION_NAME    object 
 6   MM_IN_BANK       int64  
 7   MM_W_CARD        int64  
 8   AGE              int64  
 9   GENDER           int64  
 10  EDUCATION_LEVEL  int64  
 11  MARITAL_STATUS   int64  
 12  DEPENDANT_CNT    int64  
 13  INCOME_MAIN_AMT  object 
 14  REG_CODE         float64
dtypes: float64(1), int64(10), object(4)
memory usage: 1.4+ GB
Глядя на таблицу и полученную информацию, можно сделать следующие заметки:

1) Некоторые значения являются нулевыми, их мы будем или удалять или изменять на другое значение, близкое к среднему.

2) Колонка gender где 1 это мужчины а 2 это женщины. Их будет луче переименовать заменив 1 и 2 на М и Ж.

3) Колонка SUM_TRAIN содержит числовые значения, но сами данные имеют тип object , поэтому в дальнейшем мы не сможем проводить над ним числовые и математические операции, к примеру высчитать его среднее или максимальное значение, нам нужно будет изменить тип данных в этом столбце.

4) Колонку TRANS_DTTM, необходимо перевести в формат DATETIME

Так же нам необходимо описать атрибуты, выделить самые значимые, удалить лишние  и создать новые

Начнем с изменения типов данных и NaN значений

df["SUM_TRANS"] = pd.to_numeric(df["SUM_TRANS"], errors="coerce", downcast=None) #Изменение типа данных на числовой
df.dropna(inplace=True) #Удаление нулевых значений
df['TRANS_DTTM'] = pd.to_datetime(df.TRANS_DTTM, format="%d.%m.%Y %H:%M:%S", errors="coerce") #Изменение типа данных на datatime
df.dropna(inplace=True) #Удаление нулевых значений
df.info()
<class 'pandas.core.frame.DataFrame'>
Index: 895658 entries, 295 to 12839885
Data columns (total 15 columns):
 #   Column           Non-Null Count   Dtype  
---  ------           --------------   -----  
 0   ID               895658 non-null  int64  
 1   PROD_TYPE        895658 non-null  int64  
 2   TRANS_DTTM       895658 non-null  object 
 3   MCC_CODE         895658 non-null  int64  
 4   SUM_TRANS        895658 non-null  float64
 5   LOCATION_NAME    895658 non-null  object 
 6   MM_IN_BANK       895658 non-null  int64  
 7   MM_W_CARD        895658 non-null  int64  
 8   AGE              895658 non-null  int64  
 9   GENDER           895658 non-null  int64  
 10  EDUCATION_LEVEL  895658 non-null  int64  
 11  MARITAL_STATUS   895658 non-null  int64  
 12  DEPENDANT_CNT    895658 non-null  int64  
 13  INCOME_MAIN_AMT  895658 non-null  object 
 14  REG_CODE         895658 non-null  float64
dtypes: float64(2), int64(10), object(3)
memory usage: 109.3+ MB
Затем изменим значения в столбце GENDER, на более понятные:

def gender(param): #создание функции
  if param == 1:   # условие
    return "Boy"
  else:
    return "Girl"


df.GENDER = df.GENDER.apply(gender) #применение функции к столбцу
df   #вывод результат
Далее обозначим все атрибуты:

ID – номер карты

PROD_TYPE - тип карты – кредитная или дебетовая

TRANS_DTTM – дата совершения покупки

MCC_CODE - код категории продавца

SUM_TRANS – сумма транзакции

LOCATION_NAME – название места покупки

MM_IN_BANK - общий стаж в банке, мес.

MM_W_CARD - стаж использования карты, мес.

AGE – возраст

GENDER - пол

EDUCATION_LEVEL - уровень образования

MARITAL_STATUS - семейное положение

INCOME_MAIN_AMT - уровень дохода, указанный клиентом

REG_CODE, закодированный регион регистрации клиента

 

Для выполнения задания нам необходимо добавить пару атрибутов и так же удалить.

Когда мы изменили колонку GENDR, можно сказать что мы её удалили и добавили на её место новую.

Так же мы можем разбить колонку с датой на день и время.

 

Что касается удаления атрибутов, тут каждый волен решать, что ему нужно, а что нет. Ведь для анализа можно использовать разные данные. В нашем решении мы удалим атрибут REG_CODE, так как другие параметра не зависят от него и с его помощью мы не сможем выполнить какой-либо анализ.

df = df.drop(['REG_CODE'], axis=1) #удаление 2 столбцов
df['Day'] = df.TRANS_DTTM.dt.day_name() #создание атрибута day

df['Time'] = df.TRANS_DTTM.dt.time #создание атрибута Time

df     #вывод результата на экран
Осталось выбрать для себя ключевые атрибуты, выбрать их очень просто, нужно лишь понять от каких атрибутов больше зависит мотальные данные. В нашем случае под данную характеристику подходит атрибут AGE, ведь от возраста зависят почти все остальные атрибуты. Так же можно выделить ещё пару менее значимых, но все же решаемых атрибутов, это TRANS_DTTM - дата совершения покупки и GENDER - пол покупателя, на их основе мы можем выявить различные зависимости.

После того как мы обработали данные, выделили значимые атрибуты и описали их остаётся лишь составить подробный отчет о проделанной работе и сохранить полученные данные для дальнейшей работы с ними

 df.to_csv("result.csv", index=False) #сохранение датафрейма в файл формата csv
